Сервис для загрузки документов и получения ответов на вопросы по их содержимому.
API построен на FastAPI, в качестве стора используется Chroma.

# Запуск
1. Скопировать .env.local в .env

2. Создать в личном кабинете HuggingFace токен и записать его в HF_API_TOKEN в .env.

3. Собрать и запустить контейнер:

```bash
docker compose up --build
```

После старта Swagger UI будет доступен по адресу:

```bash
http://localhost:8000/docs
```
-----------------------------------

## Краткое описание решения

Реализован минималистичный RAG-пайплайн для ответов на вопросы по загруженному документу.

### 1. Очистка текста
Документ проходит через `clean_text`: удаляются HTML-теги, BOM, экранированные символы, нормализуются переносы и Unicode. Это обеспечивает стабильную работу эмбеддинговой модели.

### 2. Разбиение документа
`split_contract` сначала выделяет смысловые разделы (например, `1.`, `2.`, `Приложение №`), затем режет их на чанки фиксированного размера с overlap.  
Чанки нумеруются (`=== CHUNK i/n ===`) для лучшей интерпретации контекста.

### 3. Построение векторного хранилища
Используется `sentence-transformers/all-mpnet-base-v2`.  
На основе чанков создаётся Chroma-хранилище (`chroma_store`). Старое удаляется при загрузке нового документа.

### 4. Поиск контекста
Retriever (`k=5`) находит релевантные чанки, которые затем объединяются в единый контекст.

### 5. Генерация ответа
LLM из HuggingFace Endpoint получает строгий промпт:
- только по документу,
- на русском,
- без галлюцинаций,
- с учётом типовой структуры договоров РФ.

Метод `ask()` выполняет: поиск контекста → генерацию ответа → логирование → сохранение истории вопросов.
